import os
import re
import requests
from bs4 import BeautifulSoup
from unidecode import unidecode

def normalize_title(title):
    # Remover acentos
    title = unidecode(title)
    # Remover pontuaÃ§Ãµes e caracteres especiais
    title = re.sub(r'[^\w\s-]', '', title)
    # Substituir espaÃ§os por hÃ­fens
    normalized_title = title.replace(" ", "-")
    # Substituir mÃºltiplos hÃ­fens por apenas um hÃ­fen
    normalized_title = re.sub(r'-{2,}', '-', normalized_title)
    # Remover preposiÃ§Ãµes, artigos e outras palavras curtas
    stopwords = ["de", "da", "do", "para", "com", "em", "e", "ou", "a", "o"]
    normalized_title = "-".join(word for word in normalized_title.split("-") if word.lower() not in stopwords)
    # Remover nÃºmeros e sublinhados restantes
    normalized_title = re.sub(r'[\d_]', '', normalized_title)
    return normalized_title.lower()

# FunÃ§Ã£o para obter a extensÃ£o da imagem a partir do cabeÃ§alho do conteÃºdo
def get_image_extension(response):
    content_type = response.headers['Content-Type']
    if 'image/jpeg' in content_type:
        return '.jpg'
    elif 'image/png' in content_type:
        return '.png'
    elif 'image/gif' in content_type:
        return '.gif'
    else:
        return '.jpg'  # PadrÃ£o para jpg se nÃ£o conseguir determinar

# CabeÃ§alhos para simular um navegador real
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# Caminho onde deseja salvar as imagens
caminho_base = "c:\\Users\\mateus.jesus\\Downloads"
pasta_imagens = "get-imagens"
caminho_salvar = os.path.join(caminho_base, pasta_imagens)

print('Bem vindo ao Get Images!  \nÃ© aqui aonde a mÃ¡gica acontece! ğŸ¥·')
# Verificar se o diretÃ³rio de imagens existe, senÃ£o criar
print('\n')
if not os.path.exists(caminho_salvar):
    os.makedirs(caminho_salvar)
    print(f"DiretÃ³rio '{pasta_imagens}' criado em '{caminho_base}'.\n")

# Perguntar ao usuÃ¡rio sobre a classe dos cards, classe do tÃ­tulo e link
class_cards = input("Por favor, digite o nome da classe dos cards: ") 
print('\n')
class_title = input("Por favor, digite o nome da classe ou tag do tÃ­tulo dos cards: ")
print('\n')
url = input("Por favor, digite o link da pÃ¡gina da web onde os cards estÃ£o localizados: ")
print('\n')

# Perguntar se o usuÃ¡rio deseja buscar imagens pela tag img ou pelo background
search_type = input("Deseja buscar imagens pela tag img? (sim/nÃ£o): ").strip().lower()
print('\n')

background_class = None
if search_type == 'nÃ£o':
    background_class = input("Por favor, digite o nome da classe do background: ")

# Fazer a requisiÃ§Ã£o HTTP para a pÃ¡gina
try:
    response = requests.get(url, headers=headers)
    response.raise_for_status()  # Isso irÃ¡ gerar um erro se a requisiÃ§Ã£o falhar
except requests.RequestException as e:
    print(f"Erro ao fazer a requisiÃ§Ã£o para a pÃ¡gina: {e}")
    exit()

# Parsear o HTML com BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# Encontrar todas as tags de classe dos cards na pÃ¡gina
cards = soup.find_all(class_=class_cards)

# Verificar se foram encontrados cards na pÃ¡gina
if not cards:
    print("Nenhum card encontrado na pÃ¡gina.")
    exit()

# ...

# Iterar sobre os cards e extrair o URL da imagem e o tÃ­tulo
for i, card in enumerate(cards):
    # Encontrar a tag do tÃ­tulo dentro do card
    title_tag = card.find(class_=class_title) or card.find(class_=class_title, href=True) or card.find("a", class_=class_title)
    if title_tag:
        title = title_tag.text.strip()
        url_imagem = None

        if search_type == 'sim':
            img_tag = card.find("img")
            if img_tag:
                url_imagem = img_tag.get("src")
            else:
                print(f"Imagem nÃ£o encontrada para o card {i}.")
                continue
        else:
            background_div = card.find(class_=background_class)
            if background_div:
                style = background_div.get('style', '')
                print(f"Card {i} - Style encontrado: {style}")  # Adicionado para depuraÃ§Ã£o
                match = re.search(r'background(?:-image)?:\s*url\(["\']?(.*?)["\']?\)', style)
                if match:
                    url_imagem = match.group(1).strip('\'"')
                    # Corrigir a URL se necessÃ¡rio (remover parÃ¢metros de dimensionamento)
                    url_imagem = re.sub(r'\?.*$', '', url_imagem)
                    print(f"Card {i} - URL da imagem de fundo encontrado: {url_imagem}")  # Adicionado para depuraÃ§Ã£o
                else:
                    print(f"Background nÃ£o encontrado para o card {i}.")
                    continue
            else:
                print(f"Div de background nÃ£o encontrada para o card {i}.")
                continue

        # Baixar a imagem
        try:
            response_imagem = requests.get(url_imagem, headers=headers, stream=True)
            response_imagem.raise_for_status()  # Isso irÃ¡ gerar um erro se a requisiÃ§Ã£o falhar
            # Obter a extensÃ£o da imagem
            extensao = get_image_extension(response_imagem)
        except requests.RequestException as e:
            print(f"Erro ao baixar a imagem do card {i}: {e}")
            continue

        # Normalizar o tÃ­tulo para o padrÃ£o desejado
        nome_arquivo = normalize_title(title)

        # Construir o caminho completo para salvar a imagem
        caminho_completo = os.path.join(caminho_salvar, f"{nome_arquivo}{extensao}")
        with open(caminho_completo, "wb") as file:
            for chunk in response_imagem.iter_content(1024):
                file.write(chunk)

        print(f"Imagem do card {title} => ( {nome_arquivo}{extensao} )")
    else:
        print("TÃ­tulo nÃ£o encontrado para o card {i}.")

# Mensagem de conclusÃ£o
print(f"\nDownload concluÃ­do! Foram baixadas {len(cards)} imagens. Confira suas imagens na pasta 'get-imagens' dentro de 'Downloads'. ğŸ‰")
